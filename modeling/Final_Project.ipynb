{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b469a7e9",
   "metadata": {},
   "source": [
    "Import cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd6578b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV, LogisticRegression, RidgeClassifier, \\\n",
    "    RidgeClassifierCV, Ridge\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "from statistics import mean\n",
    "import math \n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bdeb3a",
   "metadata": {},
   "source": [
    "# In the cell below i run a visilastion_graphe to see how my features look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d818b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visilastion_graphe(X, Y):\n",
    "    fig, axs = plt.subplots(math.ceil((len(X.columns) / 5)), 5, figsize=(15, 15))\n",
    "    fig.tight_layout()\n",
    "    count = 0\n",
    "    for col in X.columns:\n",
    "        axs[int(count / 5), count % 5].grid()\n",
    "        axs[int(count / 5), count % 5].set_title(col, color = 'red')\n",
    "        axs[int(count / 5), count % 5].hist(X[col], bins=50)\n",
    "        count += 1\n",
    "#     axs[int(count / 5), count % 5].grid()\n",
    "#     axs[int(count / 5), count % 5].hist(Y, bins=50)\n",
    "#     axs[int(count / 5), count % 5].set_title(\"Likert Raiting\", color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846ff1a",
   "metadata": {},
   "source": [
    "# In the cell below i run a multiplay models and chose a one of them as my main model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fdc6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelss(X, Y, X_Test, Y_Test):\n",
    "    models_lr = Ridge()\n",
    "    models_knn = KNeighborsRegressor(n_neighbors = 4)\n",
    "    models_cart = DecisionTreeRegressor(max_depth=10,criterion = \"absolute_error\", random_state=42)\n",
    "    models_svm = SVR(C=1.0, epsilon=0.2)\n",
    "    models_xgb = XGBRegressor(tree_method=\"hist\",eval_metric=mean_absolute_error)\n",
    "    models_randomforest = RandomForestRegressor(max_depth=14, n_estimators=50, random_state=42)\n",
    "    models = [models_lr, models_knn, models_cart, models_svm, models_xgb, models_randomforest]\n",
    "    models_name = ['Linear Regression', 'KNN', 'Decision Tree', 'SVM', 'XGB', 'Random Forest', 'Mean - Stupid', 'Common - Stupid']\n",
    "    scores = []\n",
    "    predicts = []\n",
    "    scores_val = []\n",
    "    strtfdKFold = StratifiedKFold(n_splits = 10)\n",
    "    kfold = strtfdKFold.split(X, Y)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        #X_train, Y_train = over_sample_smote(X.iloc[train, :], Y.iloc[train])\n",
    "        X_train, Y_train = X.iloc[train, :], Y.iloc[train]\n",
    "        models = list(map(lambda model: model.fit(X_train, Y_train), models))\n",
    "        predicts = list(map(lambda model: model.predict(X.iloc[test, :]), models))\n",
    "        predicts.append(np.ones(len(test))*np.mean(Y.iloc[test]))\n",
    "        predicts.append(np.ones(len(test))*Y.iloc[test].value_counts().idxmax())\n",
    "        temp = np.array(predicts)\n",
    "        temp[temp > 5] = 5\n",
    "        temp[temp < 1] = 1\n",
    "        predicts = temp\n",
    "        score = list(map(lambda predict: np.mean(np.abs(predict - Y.iloc[test])), predicts))\n",
    "        scores.append(score)\n",
    "#     models = list(map(lambda model: model.fit(X, Y), models))\n",
    "#     Test = list(map(lambda model: model.predict(X_Test), models))\n",
    "#     Test.append(np.ones(len(X_Test)) * predicts[5][1]) #'Mean - Stupid'\n",
    "#     Test.append(np.ones(len(X_Test)) * predicts[6][1]) #'Common - Stupid'\n",
    "#     score_test = list(map(lambda Test: np.mean(np.abs(Test - Y_Test)), Test))\n",
    "#     scores_test.append(score_test)\n",
    "#     ziped = zip(models_name, np.mean(scores, axis = 0),np.std(scores, axis = 0), scores_test )\n",
    "    ziped = zip(models_name, np.mean(scores, axis = 0),np.std(scores, axis = 0))\n",
    "    ziped = sorted(list(ziped), key=lambda x: x[1], reverse=False)\n",
    "    #print('\\nCross-Validation scores:\\n %3s' % (ziped))\n",
    "    return ziped, predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf7b4c",
   "metadata": {},
   "source": [
    "# In the cell below i ran a Random forest with differnt depths and then chose one of them by knee rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d625537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_desicion_of_depths(X,Y): \n",
    "    total_scores = []\n",
    "    predicts = []\n",
    "    depths = range(1,26)\n",
    "    for max_depth in depths:\n",
    "        strtfdKFold = StratifiedKFold(n_splits = 10)\n",
    "        kfold = strtfdKFold.split(X, Y)\n",
    "        scores = []\n",
    "        for k, (train, test) in enumerate(kfold):\n",
    "            model = RandomForestRegressor(max_depth = max_depth, criterion = \"absolute_error\", random_state=42)\n",
    "            model.fit(X.iloc[train, :], Y.iloc[train])\n",
    "            predict = model.predict(X.iloc[test, :])\n",
    "            score =  np.mean(np.abs(predict - Y.iloc[test]))\n",
    "            scores.append(score)\n",
    "        total_scores.append(sum(scores)/len(scores))\n",
    "    plt.plot(depths, total_scores, label=\"test\")\n",
    "    plt.xlabel('depths')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('score againts max depth of the tree')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return total_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf65ff",
   "metadata": {},
   "source": [
    "# In the cell below i ran a Random forest with differnt trees and then chose one of them by knee rule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6405f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_desicion_of_trees(X,Y):\n",
    "    total_scores = [] \n",
    "    predicts = [] \n",
    "    num_of_trees = [1, 10, 25, 50, 100, 200, 400] \n",
    "    for n in num_of_trees: \n",
    "        strtfdKFold = StratifiedKFold(n_splits = 10)\n",
    "        kfold = strtfdKFold.split(X, Y)\n",
    "        scores = [] \n",
    "        for k, (train, test) in enumerate(kfold):\n",
    "            model = RandomForestRegressor(max_depth = 14, n_estimators = n, random_state=42)\n",
    "            model.fit(X.iloc[train, :], Y.iloc[train]) \n",
    "            predict = model.predict(X.iloc[test, :]) \n",
    "            score = np.mean(np.abs(predict - Y.iloc[test])) \n",
    "            scores.append(score)\n",
    "        total_scores.append(sum(scores)/len(scores)) \n",
    "    plt.plot(num_of_trees, total_scores, label=\"test\")\n",
    "    plt.xlabel('num of trees')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('score againts num of trees')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return total_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6f4cb",
   "metadata": {},
   "source": [
    "# In the cell below i ran a Random forest my chosen depth and trees. and return my score and feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d2dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest(X,Y):\n",
    "    strtfdKFold = StratifiedKFold(n_splits = 10)\n",
    "    kfold = strtfdKFold.split(X, Y)\n",
    "    scores = [] \n",
    "    feature_importances = []\n",
    "    fetures = list(X.columns.values)\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        model = RandomForestRegressor(max_depth = 14, n_estimators = 50, random_state=42)\n",
    "        model.fit(X.iloc[train, :], Y.iloc[train]) \n",
    "        predict = model.predict(X.iloc[test, :]) \n",
    "        score = np.mean(np.abs(predict - Y.iloc[test])) \n",
    "        scores.append(score)\n",
    "        feature_importances.append(model.feature_importances_)\n",
    "    total_feature_importances = np.mean(feature_importances, axis = 0)\n",
    "    ziped = zip(fetures, total_feature_importances)\n",
    "    ziped = sorted(list(ziped), key=lambda x: x[1], reverse = True)\n",
    "    return scores, ziped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a881ab",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9809d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample_smote(X,Y):\n",
    "    oversample = SMOTE()\n",
    "    X_smote, Y_smote = oversample.fit_resample(X, Y)\n",
    "    plt.scatter(Y, range(len(Y)), label = 'original')\n",
    "    plt.scatter(Y_smote[len(Y)+1:], range(len(Y)+1,len(Y_smote)) , label = 'resampling with smote')\n",
    "    plt.legend()\n",
    "    plt.ylabel('id of sample')\n",
    "    plt.xlabel('value of sample')\n",
    "    plt.show()\n",
    "    return  X_smote, Y_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3979d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample_adasyn(X,Y):\n",
    "    oversample = ADASYN()\n",
    "    X_smote, Y_smote = oversample.fit_resample(X, Y)\n",
    "    plt.scatter(Y, range(len(Y)), label = 'original')\n",
    "    plt.scatter(Y_smote[len(Y)+1:], range(len(Y)+1,len(Y_smote)) , label = 'resampling with smote')\n",
    "    plt.legend()\n",
    "    plt.ylabel('id of sample')\n",
    "    plt.xlabel('value of sample')\n",
    "    plt.show()\n",
    "    return  X_smote, Y_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451869dc",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8f1b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"result_final.csv\")\n",
    "df = df.fillna(0)\n",
    "X = df.drop(['Likert Raiting', 'URL', 'Original row ID'], axis=1)  # features\n",
    "Y = df['Likert Raiting']  # labels\n",
    "selector = SelectKBest(chi2, k = 15)\n",
    "selctor = selector.fit(X, Y)\n",
    "mask = selector.get_feature_names_out()\n",
    "X_chi = X[mask]\n",
    "\n",
    "df1 = pd.read_csv(r\"secondary_final.csv\")\n",
    "df1 = df1.fillna(0)\n",
    "X_Test = df1.drop(['Likert Raiting', 'URL', 'Original row ID', 'edu', 'biz', 'info', 'io','Rater ID'], axis=1)  # features\n",
    "Y_Test = df1['Likert Raiting']  # labels\n",
    "\n",
    "# X_smote, Y_smote = over_sample_smote(X,Y)\n",
    "# X_adasyn, Y_adasyn = over_sample_adasyn(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e6c7495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result Rank</th>\n",
       "      <th>Links</th>\n",
       "      <th>a tags</th>\n",
       "      <th>Word count</th>\n",
       "      <th>Misspelled words</th>\n",
       "      <th>misspelled_percent (%)</th>\n",
       "      <th>Char count</th>\n",
       "      <th>Img count</th>\n",
       "      <th>Banner count</th>\n",
       "      <th>Link depth</th>\n",
       "      <th>Special characters</th>\n",
       "      <th>Outdated dates</th>\n",
       "      <th>com</th>\n",
       "      <th>net</th>\n",
       "      <th>edu</th>\n",
       "      <th>biz</th>\n",
       "      <th>gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.71</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>17.79</td>\n",
       "      <td>4256.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>12.62</td>\n",
       "      <td>5527.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>25.52</td>\n",
       "      <td>8434.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>16.17</td>\n",
       "      <td>4901.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2461.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>8.17</td>\n",
       "      <td>19106.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>37.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>13.54</td>\n",
       "      <td>6799.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>23.11</td>\n",
       "      <td>5792.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>16.20</td>\n",
       "      <td>7257.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>802 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Result Rank  Links  a tags  Word count  Misspelled words  \\\n",
       "0            2.0    3.0    81.0       146.0              39.0   \n",
       "1            3.0    4.0   174.0       461.0              82.0   \n",
       "2            4.0    4.0    49.0       737.0              93.0   \n",
       "3            5.0    7.0   247.0       921.0             235.0   \n",
       "4            6.0    1.0   114.0       600.0              97.0   \n",
       "..           ...    ...     ...         ...               ...   \n",
       "797         36.0   14.0   193.0      2461.0             201.0   \n",
       "798         37.0   12.0   173.0       746.0             101.0   \n",
       "799         38.0    5.0    97.0       649.0             150.0   \n",
       "800         39.0    3.0     7.0       333.0              14.0   \n",
       "801         40.0    5.0   192.0       920.0             149.0   \n",
       "\n",
       "     misspelled_percent (%)  Char count  Img count  Banner count  Link depth  \\\n",
       "0                     26.71      1341.0       36.0           0.0         2.0   \n",
       "1                     17.79      4256.0       70.0           0.0         2.0   \n",
       "2                     12.62      5527.0        9.0           0.0         3.0   \n",
       "3                     25.52      8434.0       47.0           0.0         3.0   \n",
       "4                     16.17      4901.0      100.0           1.0         0.0   \n",
       "..                      ...         ...        ...           ...         ...   \n",
       "797                    8.17     19106.0       18.0           0.0         0.0   \n",
       "798                   13.54      6799.0       39.0           2.0         3.0   \n",
       "799                   23.11      5792.0       51.0           3.0         3.0   \n",
       "800                    4.20      2440.0        4.0           0.0         0.0   \n",
       "801                   16.20      7257.0       14.0           1.0         1.0   \n",
       "\n",
       "     Special characters  Outdated dates  com  net  edu  biz  gov  \n",
       "0                   3.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1                   3.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2                  12.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "3                   5.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4                   3.0             0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "..                  ...             ...  ...  ...  ...  ...  ...  \n",
       "797                 2.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "798                 9.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "799                 4.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "800                 3.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "801                 5.0             0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[802 rows x 17 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d53b1a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>MAE</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.746862</td>\n",
       "      <td>0.052327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.760002</td>\n",
       "      <td>0.037592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common - Stupid</td>\n",
       "      <td>0.794259</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.796386</td>\n",
       "      <td>0.063774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.821787</td>\n",
       "      <td>0.009757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.838086</td>\n",
       "      <td>0.098874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean - Stupid</td>\n",
       "      <td>0.866809</td>\n",
       "      <td>0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.045038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MODEL       MAE       STD\n",
       "0      Random Forest  0.746862  0.052327\n",
       "1  Linear Regression  0.760002  0.037592\n",
       "2    Common - Stupid  0.794259  0.008436\n",
       "3                XGB  0.796386  0.063774\n",
       "4                SVM  0.821787  0.009757\n",
       "5      Decision Tree  0.838086  0.098874\n",
       "6      Mean - Stupid  0.866809  0.006216\n",
       "7                KNN  0.874900  0.045038"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visilastion_graphe(normalized_min_max, Y)\n",
    "ziped, predicts = modelss(X_chi, Y, X_Test, Y_Test)\n",
    "# ziped_smote, predicts_smote = modelss(X_smote, Y_smote, X_val, Y_val)\n",
    "# ziped_adasyn, predicts_smote = modelss(X_adasyn, Y_adasyn, X_val, Y_val)\n",
    "#total_score = Random_Forest_desicion_of_depths(X,Y)\n",
    "#total_score2 = Random_Forest_desicion_of_trees(X,Y)\n",
    "#score, feature_importance = Random_Forest(X,Y)\n",
    "# all_models_adasyn = pd.DataFrame(ziped_adasyn,  columns =['MODEL', 'MAE with adasyn', 'STD with adasyn', 'Val score with adasyn'])\n",
    "# all_models_smote = pd.DataFrame(ziped_smote,  columns =['MODEL', 'MAE with smote', 'STD with smote', 'Val score with smote'])\n",
    "#all_models = pd.DataFrame(ziped,  columns =['MODEL', 'MAE', 'STD', 'Val score'])\n",
    "all_models = pd.DataFrame(ziped,  columns =['MODEL', 'MAE', 'STD'])\n",
    "\n",
    "\n",
    "#feature_importance = pd.DataFrame(feature_importance,  columns =['feature name', 'importance'])\n",
    "#pd.concat([all_models, all_models_smote, all_models_adasyn], axis=1)\n",
    "all_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
